{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ATE-Estimation-with-Machine-Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vveitch/causality-tutorials/blob/main/ATE_Estimation_with_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfZkNLUb4B-p"
      },
      "source": [
        "# ATT Estimation Tutorial\n",
        "\n",
        "This tutorial gives a short example for how to estimate average treatment effect on the treated using machine learning methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS2X3Bq1-fxE"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import mean_squared_error, log_loss\n",
        "import sklearn\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPbJeayiEs3u"
      },
      "source": [
        "##Load and Format LaLonde Observational Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AC9TPko-hbt"
      },
      "source": [
        "def make_data_lalonde(df):\n",
        "    df_new = df.drop(['nodegree'], axis=1)\n",
        "    df_new['pos74'] = (df_new['RE74'] > 0).astype(int)\n",
        "    df_new['pos75'] = (df_new['RE75'] > 0).astype(int)\n",
        "    df_new['treatment'] = df_new['treatment'].astype(int)\n",
        "    return df_new\n",
        "\n",
        "\n",
        "col_names = ['treatment', 'age', 'education', 'black',\n",
        "             'hispanic', 'married', 'nodegree', 'RE74', 'RE75', 'RE78']\n",
        "control = pd.read_csv('https://raw.githubusercontent.com/anishazaveri/austen_plots/master/data/imbens-raw/psid_controls.txt', header=None, sep=r\"\\s\\s\", names=col_names, engine='python')\n",
        "treatment = pd.read_csv('https://raw.githubusercontent.com/anishazaveri/austen_plots/master/data/imbens-raw/nswre74_treated.txt', header=None, sep=r\"\\s\\s\", names=col_names, engine='python')\n",
        "\n",
        "lalonde1 = pd.concat([control, treatment]).reset_index(drop=True)\n",
        "lalonde1 = make_data_lalonde(lalonde1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "-A1LX6-t-hZD",
        "outputId": "e30d1748-aac8-4d28-ded8-f8b263ebd6da"
      },
      "source": [
        "lalonde1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>treatment</th>\n",
              "      <th>age</th>\n",
              "      <th>education</th>\n",
              "      <th>black</th>\n",
              "      <th>hispanic</th>\n",
              "      <th>married</th>\n",
              "      <th>RE74</th>\n",
              "      <th>RE75</th>\n",
              "      <th>RE78</th>\n",
              "      <th>pos74</th>\n",
              "      <th>pos75</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   treatment   age  education  black  hispanic  ...  RE74  RE75  RE78  pos74  pos75\n",
              "0          0  47.0       12.0    0.0       0.0  ...   0.0   0.0   0.0      0      0\n",
              "1          0  50.0       12.0    1.0       0.0  ...   0.0   0.0   0.0      0      0\n",
              "2          0  44.0       12.0    0.0       0.0  ...   0.0   0.0   0.0      0      0\n",
              "3          0  28.0       12.0    1.0       0.0  ...   0.0   0.0   0.0      0      0\n",
              "4          0  54.0       12.0    0.0       0.0  ...   0.0   0.0   0.0      0      0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 458
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APOqpHmrOGzo"
      },
      "source": [
        "confounders = lalonde1.drop(columns=['RE78', 'treatment'])\n",
        "outcome = lalonde1['RE78']\n",
        "treatment = lalonde1['treatment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C576dWRsa3ad"
      },
      "source": [
        "## Specify Nuisance Function Models\n",
        "\n",
        "The next step is to specify models for the conditional expected outcome and propensity score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyOhSZRQRb8W",
        "outputId": "a714aa01-537b-4fc8-9655-5a8d4ac9a064"
      },
      "source": [
        "# specify a model for the conditional expected outcome\n",
        "\n",
        "# make a function that returns a sklearn model for later use in k-folding\n",
        "def make_Q_model():\n",
        "  return RandomForestRegressor(random_state=RANDOM_SEED, n_estimators=500, max_depth=None)\n",
        "Q_model = make_Q_model()\n",
        "\n",
        "# Sanity check that chosen model actually improves test error\n",
        "# A real analysis should give substantial attention to model selection and validation \n",
        "\n",
        "X_w_treatment = confounders.copy()\n",
        "X_w_treatment[\"treatment\"] = treatment\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_w_treatment, outcome, test_size=0.2)\n",
        "Q_model.fit(X_train, y_train)\n",
        "y_pred = Q_model.predict(X_test)\n",
        "\n",
        "test_mse=mean_squared_error(y_pred, y_test)\n",
        "print(f\"Test MSE of fit model {test_mse}\") \n",
        "baseline_mse=mean_squared_error(y_train.mean()*np.ones_like(y_test), y_test)\n",
        "print(f\"Test MSE of no-covariate model {baseline_mse}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MSE of fit model 105637760.68507269\n",
            "Test MSE of no-covariate model 246319790.55062827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq6eZEBXbsaI",
        "outputId": "aeaaf4be-485a-4d7a-94c6-59d0fd1f50dd"
      },
      "source": [
        "# specify a model for the propensity score\n",
        "\n",
        "def make_g_model():\n",
        "#  return LogisticRegression(max_iter=1000)\n",
        "  return RandomForestClassifier(n_estimators=100, max_depth=5)\n",
        "\n",
        "g_model = make_g_model()\n",
        "# Sanity check that chosen model actually improves test error\n",
        "# A real analysis should give substantial attention to model selection and validation \n",
        "\n",
        "X_train, X_test, a_train, a_test = train_test_split(confounders, treatment, test_size=0.2)\n",
        "g_model.fit(X_train, a_train)\n",
        "a_pred = g_model.predict_proba(X_test)[:,1]\n",
        "\n",
        "test_ce=log_loss(a_test, a_pred)\n",
        "print(f\"Test CE of fit model {test_ce}\") \n",
        "baseline_ce=log_loss(a_test, a_train.mean()*np.ones_like(a_test))\n",
        "print(f\"Test CE of no-covariate model {baseline_ce}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test CE of fit model 0.07789407933364972\n",
            "Test CE of no-covariate model 0.21817471356014154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RkvV_4_dFWo"
      },
      "source": [
        "## Use cross fitting to get get predicted outcomes and propensity scores for each unit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA0AsEGJ_X3b"
      },
      "source": [
        "# helper functions to implement the cross fitting\n",
        "\n",
        "def treatment_k_fold_fit_and_predict(make_model, X:pd.DataFrame, A:np.array, n_splits:int):\n",
        "    \"\"\"\n",
        "    Implements K fold cross-fitting for the model predicting the treatment A. \n",
        "    That is, \n",
        "    1. Split data into K folds\n",
        "    2. For each fold j, the model is fit on the other K-1 folds\n",
        "    3. The fitted model is used to make predictions for each data point in fold j\n",
        "    Returns an array containing the predictions  \n",
        "\n",
        "    Args:\n",
        "    model: function that returns sklearn model (which implements fit and predict_prob)\n",
        "    X: dataframe of variables to adjust for\n",
        "    A: array of treatments\n",
        "    n_splits: number of splits to use\n",
        "    \"\"\"\n",
        "    predictions = np.full_like(A, np.nan, dtype=float)\n",
        "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
        "    \n",
        "    for train_index, test_index in kf.split(X, A):\n",
        "      X_train = X.loc[train_index]\n",
        "      A_train = A.loc[train_index]\n",
        "      g = make_model()\n",
        "      g.fit(X_train, A_train)\n",
        "\n",
        "      # get predictions for split\n",
        "      predictions[test_index] = g.predict_proba(X.loc[test_index])[:, 1]\n",
        "\n",
        "    assert np.isnan(predictions).sum() == 0\n",
        "    return predictions\n",
        "\n",
        "\n",
        "def outcome_k_fold_fit_and_predict(make_model, X:pd.DataFrame, y:np.array, A:np.array, n_splits:int, output_type:str):\n",
        "    \"\"\"\n",
        "    Implements K fold cross-fitting for the model predicting the outcome Y. \n",
        "    That is, \n",
        "    1. Split data into K folds\n",
        "    2. For each fold j, the model is fit on the other K-1 folds\n",
        "    3. The fitted model is used to make predictions for each data point in fold j\n",
        "    Returns two arrays containing the predictions for all units untreated, all units treated  \n",
        "\n",
        "    Args:\n",
        "    model: function that returns sklearn model (that implements fit and either predict_prob or predict)\n",
        "    X: dataframe of variables to adjust for\n",
        "    y: array of outcomes\n",
        "    A: array of treatments\n",
        "    n_splits: number of splits to use\n",
        "    output_type: type of outcome, \"binary\" or \"continuous\"\n",
        "\n",
        "    \"\"\"\n",
        "    predictions0 = np.full_like(A, np.nan, dtype=float)\n",
        "    predictions1 = np.full_like(y, np.nan, dtype=float)\n",
        "    if output_type == 'binary':\n",
        "      kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
        "    elif output_type == 'continuous':\n",
        "      kf = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
        "\n",
        "    # include the treatment as input feature\n",
        "    X_w_treatment = X.copy()\n",
        "    X_w_treatment[\"A\"] = A\n",
        "\n",
        "    # for predicting effect under treatment / control status for each data point \n",
        "    X0 = X_w_treatment.copy()\n",
        "    X0[\"A\"] = 0\n",
        "    X1 = X_w_treatment.copy()\n",
        "    X1[\"A\"] = 1\n",
        "\n",
        "    \n",
        "    for train_index, test_index in kf.split(X_w_treatment, y):\n",
        "      X_train = X_w_treatment.loc[train_index]\n",
        "      y_train = y.loc[train_index]\n",
        "      q = make_model()\n",
        "      q.fit(X_train, y_train)\n",
        "\n",
        "      if output_type =='binary':\n",
        "        predictions0[test_index] = q.predict_proba(X0.loc[test_index])[:, 1]\n",
        "        predictions1[test_index] = q.predict_proba(X1.loc[test_index])[:, 1]\n",
        "      elif output_type == 'continuous':\n",
        "        predictions0[test_index] = q.predict(X0.loc[test_index])\n",
        "        predictions1[test_index] = q.predict(X1.loc[test_index])\n",
        "\n",
        "    assert np.isnan(predictions0).sum() == 0\n",
        "    assert np.isnan(predictions1).sum() == 0\n",
        "    return predictions0, predictions1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVcE6pRQeMNf"
      },
      "source": [
        "g = treatment_k_fold_fit_and_predict(make_g_model, X=confounders, A=treatment, n_splits=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLEHlLLdWSh9"
      },
      "source": [
        "Q0,Q1=outcome_k_fold_fit_and_predict(make_Q_model, X=confounders, y=outcome, A=treatment, n_splits=10, output_type=\"continuous\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "_NVCV0q0g8wQ",
        "outputId": "86692800-b7fa-4fd8-f4f1-0871d64c3de0"
      },
      "source": [
        "data_and_nuisance_estimates = pd.DataFrame({'g': g, 'Q0': Q0, 'Q1': Q1, 'A': treatment, 'Y': outcome})\n",
        "data_and_nuisance_estimates.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g</th>\n",
              "      <th>Q0</th>\n",
              "      <th>Q1</th>\n",
              "      <th>A</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.313350</td>\n",
              "      <td>95.549536</td>\n",
              "      <td>1571.922518</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.191958</td>\n",
              "      <td>2032.024647</td>\n",
              "      <td>3895.070486</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.470788</td>\n",
              "      <td>29.940432</td>\n",
              "      <td>1731.498259</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.517957</td>\n",
              "      <td>11037.487272</td>\n",
              "      <td>9030.776610</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.014246</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2139.630960</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          g            Q0           Q1  A    Y\n",
              "0  0.313350     95.549536  1571.922518  0  0.0\n",
              "1  0.191958   2032.024647  3895.070486  0  0.0\n",
              "2  0.470788     29.940432  1731.498259  0  0.0\n",
              "3  0.517957  11037.487272  9030.776610  0  0.0\n",
              "4  0.014246      0.000000  2139.630960  0  0.0"
            ]
          },
          "metadata": {},
          "execution_count": 465
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNhM7URdgzQB"
      },
      "source": [
        "## Combine predicted values and data into estimate of ATT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-vONC5ejwh2"
      },
      "source": [
        "def att_aiptw(Q0, Q1, g, A, Y, prob_t=None):\n",
        "  \"\"\"\n",
        "  # Double ML estimator for the ATT\n",
        "  This uses the ATT specific scores, see equation 3.9 of https://www.econstor.eu/bitstream/10419/149795/1/869216953.pdf\n",
        "  \"\"\"\n",
        "\n",
        "  if prob_t is None:\n",
        "    prob_t = A.mean() # estimate marginal probability of treatment\n",
        "\n",
        "  tau_hat = (A*(Y-Q0) - (1-A)*(g/(1-g))*(Y-Q0)).mean()/ prob_t\n",
        "  \n",
        "  scores = (A*(Y-Q0) - (1-A)*(g/(1-g))*(Y-Q0) - tau_hat*A) / prob_t\n",
        "  n = Y.shape[0] # number of observations\n",
        "  std_hat = np.std(scores) / np.sqrt(n)\n",
        "\n",
        "  return tau_hat, std_hat\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_F5r0SSkzzK"
      },
      "source": [
        "def ate_aiptw(Q0, Q1, g, A, Y, prob_t=None):\n",
        "  \"\"\"\n",
        "  # Double ML estimator for the ATE\n",
        "  \"\"\"\n",
        "\n",
        "  tau_hat = (Q1 - Q0 + A*(Y-Q1)/g - (1-A)*(Y-Q0)/(1-g)).mean()\n",
        "  \n",
        "  scores = Q1 - Q0 + A*(Y-Q1)/g - (1-A)*(Y-Q0)/(1-g) - tau_hat\n",
        "  n = Y.shape[0] # number of observations\n",
        "  std_hat = np.std(scores) / np.sqrt(n)\n",
        "\n",
        "  return tau_hat, std_hat\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjDj0F9Bm9uq",
        "outputId": "42c4eabf-b32b-46df-9323-cf99698dc2f5"
      },
      "source": [
        "tau_hat, std_hat = att_aiptw(**data_and_nuisance_estimates)\n",
        "print(f\"The estimate is {tau_hat} pm {1.96*std_hat}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0691588785046729\n",
            "0.06859258880246219\n",
            "The estimate is 1300.9807431649592 pm 1622.6924287596182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSaOp1HwlQ4i",
        "outputId": "1697f317-63a4-4754-b76c-9e7e7433812a"
      },
      "source": [
        "in_treated = data_and_nuisance_estimates['A']==1\n",
        "treated_estimates = data_and_nuisance_estimates[in_treated]\n",
        "tau_hat, std_hat = ate_aiptw(**treated_estimates)\n",
        "print(f\"The estimate is {tau_hat} pm {1.96*std_hat}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.17127377098855\n",
            "The estimate is -33439.05484914103 pm 50637.28008886066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOuJnlbEo8j_",
        "outputId": "bff27d70-c0e9-4cb6-d55e-8dc27b86aa1a"
      },
      "source": [
        "# The LaLonde data has severe overlap issues. Lets try computing the estimate restricted to a population with only reasonable propensity scores\n",
        "g = data_and_nuisance_estimates['g']\n",
        "in_overlap_popluation = ( g < 0.90)\n",
        "overlap_data_and_nuisance = data_and_nuisance_estimates[in_overlap_popluation]\n",
        "tau_hat, std_hat = att_aiptw(**overlap_data_and_nuisance)\n",
        "print(f\"The estimate is {tau_hat} pm {1.96*std_hat}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The estimate is 572.1572812652179 pm 1501.516696945994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLn-2lWvXnDq",
        "outputId": "98032d45-73de-48dc-c453-b866941afe53"
      },
      "source": [
        "g = data_and_nuisance_estimates.g\n",
        "np.mean(g/(1-g) > 5)\n",
        "#np.mean(data_and_nuisance_estimates['A'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.031401869158878506"
            ]
          },
          "metadata": {},
          "execution_count": 471
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnJppbQdjwVI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}